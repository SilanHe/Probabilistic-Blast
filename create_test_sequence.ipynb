{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sequence and probabilities into memory\n",
    "sequence_filename = \"chr22.maf.ancestors.42000000.complete.boreo.fa.txt\"\n",
    "probabilities_filename = \"chr22.maf.ancestors.42000000.complete.boreo.conf.txt\"\n",
    "\n",
    "with open(sequence_filename) as f:\n",
    "    sequence = f.readline()\n",
    "\n",
    "with open(probabilities_filename) as f:\n",
    "    probabilities = f.readline().split()\n",
    "\n",
    "# make all probabilities float\n",
    "n = len(probabilities)\n",
    "for i in range(n):\n",
    "    probabilities[i] = float(probabilities[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "import random\n",
    "import math\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate test sequence"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 16,

   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_sequence(length,prob_insertion,prob_deletion, prob_point):\n",
    "    nucleotides = ['A', 'G', 'C', 'T']\n",
    "    \n",
    "    # get random starting position\n",
    "    \n",
    "    len_sequence = len(sequence)\n",
    "    # len of probabilities should be the same\n",
    "    \n",
    "    start_index = random.randrange(len_sequence-length-1)\n",
    "    \n",
    "    query = list()\n",
    "    \n",
    "    for i in range(start_index, start_index+length):\n",
    "        insertion = list()\n",
    "        extra_nucleotide = \"\"\n",
    "        \n",
    "        if (probabilities[i] > random.random()):\n",
    "                nucleotide = sequence[i]\n",
    "        else:\n",
    "            temp_nucleotides = ['A', 'G', 'C', 'T']\n",
    "            temp_nucleotides.remove(sequence[i])\n",
    "            nucleotide = temp_nucleotides[random.randrange(3)]\n",
    "        \n",
    "        insertion_deletion_prob = random.random()\n",
    "        \n",
    "        if insertion_deletion_prob < prob_insertion:\n",
    "            # if we are within probability of getting an insertion \n",
    "            # length follows a geometric distribution\n",
    "            insertion_length = int(math.log(random.random()/prob_insertion)/math.log(1-prob_insertion) + 1)\n",
    "            for i in range(insertion_length):\n",
    "                extra_nucleotide = nucleotides[random.randrange(4)] \n",
    "                insertion.append(extra_nucleotide)\n",
    "\n",
    "        elif insertion_deletion_prob < prob_insertion + prob_deletion:\n",
    "            # if we are within probability of getting a deletion\n",
    "            nucleotide = \"\"\n",
    "           \n",
    "        elif insertion_deletion_prob < prob_insertion + prob_deletion + prob_point:\n",
    "            nucleotide = nucleotides[random.randrange(4)]\n",
    "  \n",
    "        query.append(nucleotide + \"\".join(insertion))\n",
    "    \n",
    "    return [\"\".join(query),start_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,

   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GCTAGCTAGAGTTTTACCTTTTAGGGAAGAGAACTTAGAAAATGGAGATTGGGTCTTTGACCAACAGCAAATAGAGGAAATTGATTTTCCATATATTTCT',\n",
       " 140891]"
      ]
     },

     "execution_count": 17,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_test_sequence(100, 0.0005, 0.0005, 0.005)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 18,

   "metadata": {},
   "outputs": [],
   "source": [
    "# test_name = \"test_sequence\"\n",
    "# new_filename = test_name + \".fa\"\n",
    "\n",
    "# length = 300\n",
    "# prob_insertion = 0.01\n",
    "# prob_deletion = 0.01\n",
    "\n",
    "# test_sequence_list = get_test_sequence(length,prob_insertion,prob_deletion)\n",
    "\n",
    "# with open(new_filename, 'w') as f:\n",
    "#     f.write(\">\" + test_name + \" \" + str(test_sequence_list[1]) + \" \" + str(length) + \"\\n\")\n",
    "#     f.write(test_sequence_list[0])"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 19,

   "metadata": {},
   "outputs": [],
   "source": [
    "import blast\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 20,

   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_test_probabilistic_blast(test_name: str,iterations: int):\n",
    "    \n",
    "    cur_dir = os.getcwd()\n",
    "    os.mkdir(test_name)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        \n",
    "        new_filename = test_name +  str(i) + \".fa\"\n",
    "        new_path_to_file = os.path.join(cur_dir, test_name, new_filename)\n",
    "\n",
    "        length = 400\n",
    "        prob_insertion = 0.0005\n",
    "        prob_deletion = 0.0005\n",
    "        prob_point = 0.005\n",
    "\n",
    "        test_sequence_list = get_test_sequence(length,prob_insertion,prob_deletion,prob_point)\n",
    "\n",
    "        with open(new_path_to_file, 'w') as f:\n",
    "            f.write(\">\" + test_name + \" \" + str(test_sequence_list[1]) + \" \" + str(length) + \"\\n\")\n",
    "            f.write(test_sequence_list[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gen_test_probabilistic_blast(\"testing_suite_2\",100)\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1: 0 10 100\n",
    "# test 2: 0 45 100\n",
    "# test 3: 0 45 100\n",
    "\n",
    "# test 3 with epsilon 0 : 0 0 100\n",
    "# test 3 with epsilon 10: 0 46 100\n",
    "# test 3 with epsilon 15: [0, 44, 0, 100]\n",
    "\n",
    "# higher epsilon is better\n",
    "\n",
    "# test 3 with top ten: 0 45 0 100\n",
    "# test 4: 0 45 0 100\n",
    "# test 5: 0 45 0 100\n",
    "\n",
    "# test 3\n",
    "\n",
    "# alpha 0.8 [0, 45, 0, 100, 44.18176678]\n",
    "# alpha 0.9 [0, 46, 0, 100, 45.725060700000014]\n",
    "# alpha 0.95 [0, 45, 0, 100, 43.92756490000005]\n",
    "\n",
    "# beta 25 [0, 45, 0, 100, 108.04912073999995]\n",
    "\n",
    "# delta 1 [0, 46, 0, 100, 51.59618474000002]\n",
    "# delta 10 [0, 45, 0, 100, 43.11371054000002]\n",
    "\n",
    "# final tests word size 5\n",
    "\n",
    "# base params  [1, 11, 83, 1, 0.0, 0.0, 0.0, 100, 30.060828680000004]\n",
    "# delta 20 [1, 11, 83, 1, 0.0, 0.0, 0.0, 100, 29.526636300000035]\n"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 21,

   "metadata": {},
   "outputs": [],
   "source": [
    "def test_probabilistic_blast(test_name: str,pblast: blast.PBlast):\n",
    "    \n",
    "    exact_index_matches = 0\n",
    "    contains_match = 0\n",
    "    contains_start = 0\n",
    "    contains_end = 0\n",
    "    total_time = 0\n",
    "    topten = 0\n",
    "    topten_contains_start = 0\n",
    "    topten_contains_end = 0\n",
    "    \n",
    "    \n",
    "    cur_dir = os.getcwd()\n",
    "    test_dir = os.path.join(cur_dir, test_name) \n",
    "    \n",
    "    files = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(test_dir):\n",
    "        for file in f:\n",
    "            if '.fa' in file:\n",
    "                files.append(os.path.join(r, file))\n",
    "    \n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        #read first line of fasta file\n",
    "        with open(file, 'r') as f:\n",
    "            info = f.readline().split()\n",
    "            start_index = int(info[1])\n",
    "            length = int(info[2])\n",
    "        \n",
    "        # call to probabilistic blast\n",
    "        pblast.load_query_file(file)\n",
    "        \n",
    "        # compare with start and end index locations\n",
    "        start_time = time.process_time()\n",
    "        result = pblast.probabilistic_blast()\n",
    "        end_time = time.process_time()\n",
    "        \n",
    "        total_time += end_time - start_time\n",
    "        \n",
    "        if start_index == result[-1][0] and result[-1][1] - result[-1][0] == length:\n",
    "            exact_index_matches += 1\n",
    "        elif start_index <= result[-1][0] and result[-1][1] - result[-1][0] >= length:\n",
    "            contains_match += 1\n",
    "        elif start_index < result[-1][1] and result[-1][1] < start_index + length:\n",
    "            # contains part of the start of the query\n",
    "            contains_start += 1\n",
    "        elif result[-1][0] < start_index + length and start_index + length < result[-1][1]:\n",
    "            # contains part of the end of the query\n",
    "            contains_end += 1\n",
    "        \n",
    "        # check top ten results as well\n",
    "        \n",
    "        for j in range(-10,-1,-1):\n",
    "            if start_index[1] <= result[j][0] and result[j][1] - result[j][0] >= length:\n",
    "                topten += 1\n",
    "            elif start_index < result[-1][1] and result[-1][1] < start_index + length:\n",
    "                # contains part of the start of the query\n",
    "                contains_start += 1\n",
    "            elif result[-1][0] < start_index + length and start_index + length < result[-1][1]:\n",
    "                # contains part of the end of the query\n",
    "                contains_end += 1\n",
    "    \n",
    "    iterations = len(files)\n",
    "    return [exact_index_matches,contains_match,contains_start,contains_end,topten/iterations,topten_contains_start/iterations,topten_contains_end/iterations,iterations,total_time/iterations]\n",
    "\n"
   ]
  },
}